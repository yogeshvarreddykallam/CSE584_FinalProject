{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b3d97-d545-4d34-8ae3-1a19f6295c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk-proj-PirjYMqo6HuPi7bfVSdlNte46f09zqamsyjRK4AT3BlbkFJGgMbVXh9lF9RmBzSY_3TY9oUzqYv05azF9plFCSDJDVZ4Q-AsKFUN95GP9SLwCeg0IcOyONCoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dde57afc-e5d2-4cbf-a3c0-6a60e140f526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='Code calls on itself,  \\nMirrors in endless fractals—  \\nLoops whisper secrets.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae410515-81b3-4bbc-9b92-dd5934b40a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code within itself,  \n",
      "Endless loops echo in depth—  \n",
      "A fractal of thought.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Instantiate the client\n",
    "client = OpenAI()\n",
    "\n",
    "# Create a chat completion\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",  # Note: Ensure 'gpt-4o' is available in your OpenAI account\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a haiku about recursion in programming.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the message content directly\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a28f342e-1e07-45b9-9f3b-a0ccb77120d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AYQVlkCAvRtWHWuNOehsGG574cjYg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The idea of a car, or any object with mass, traveling faster than the speed of light is not possible according to our current understanding of physics. According to Einstein's theory of relativity, as an object with mass accelerates toward the speed of light, its relativistic mass increases, requiring more and more energy to continue accelerating. It would take an infinite amount of energy for such an object to reach the speed of light, making it impossible.\\n\\nThe concept of traveling faster than light and going back in time is often explored in science fiction, but it lacks a basis in established physical theory. In relativity, the speed of light is the cosmic speed limit, and causality (the relationship between cause and effect) is preserved as long as this limit is not exceeded.\\n\\nThere are hypothetical particles called tachyons that are theorized to travel faster than light, but they remain purely speculative and have not been observed. Even if they did exist, they would not necessarily imply the possibility of time travel in any practical sense.\\n\\nIn summary, based on our current understanding of physics, traveling faster than the speed of light and going back in time is not possible.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732768425, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_7f6be3efb0', usage=CompletionUsage(completion_tokens=232, prompt_tokens=36, total_tokens=268, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-AYQVppw2tuAqHviu8yWT5q9ZeDE5h', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A perpetual motion machine is a hypothetical device that can operate indefinitely without an external energy source, effectively producing more energy than it consumes. According to the laws of physics, particularly the first and second laws of thermodynamics, such a machine is impossible.\\n\\n1. **First Law of Thermodynamics (Conservation of Energy)**: This law states that energy cannot be created or destroyed, only transformed from one form to another. A perpetual motion machine of the first kind would violate this law by creating energy from nothing.\\n\\n2. **Second Law of Thermodynamics (Entropy)**: This law states that entropy, or disorder, in an isolated system will tend to increase over time. It implies that energy transformations are not 100% efficient, as some energy is always lost as waste heat. A perpetual motion machine of the second kind would violate this law by converting all the energy into work with perfect efficiency.\\n\\nNo known material or technology can circumvent these fundamental laws of physics. While improvements in materials and technology can increase the efficiency of energy systems, they cannot eliminate energy losses entirely or create energy from nothing. Therefore, creating a perpetual motion machine remains impossible according to our current understanding of physics.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732768429, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_831e067d82', usage=CompletionUsage(completion_tokens=234, prompt_tokens=33, total_tokens=267, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "ChatCompletion(id='chatcmpl-AYQVsFPYY5BWzWBP7aHEt7uEUCAn2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"No, gravity affects all objects with mass, regardless of their size. According to Newton's law of universal gravitation, every object with mass attracts every other object with mass through the force of gravity. This means that not only do massive objects like planets and stars exert gravitational forces, but smaller objects, like people and even tiny particles, do as well. However, the gravitational force is directly proportional to the product of the masses of the objects and inversely proportional to the square of the distance between them. This means that while all masses exert gravitational forces, the effect is much more noticeable with massive objects, like planets and stars, because their larger mass results in a stronger gravitational pull. In contrast, the gravitational force between small objects, like everyday items, is usually too weak to be noticeable.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732768432, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_831e067d82', usage=CompletionUsage(completion_tokens=159, prompt_tokens=29, total_tokens=188, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "                                                                       Question                                              Answer\n",
      "\"If a car is traveling faster than the speed of light, can it go back in time?\" Error: 'ChatCompletion' object is not subscriptable\n",
      " \"Can we create a perpetual motion machine if we just use the right materials?\" Error: 'ChatCompletion' object is not subscriptable\n",
      "             \"Does gravity only affect massive objects like planets and stars?\" Error: 'ChatCompletion' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "openai.api_key = \"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\"  # Replace with your actual OpenAI API key\n",
    "\n",
    "# Load the questions from the Excel file\n",
    "file_path = \"only_question.xlsx\"  # Ensure the file is in the same directory or provide the full path\n",
    "questions_df = pd.read_excel(file_path)\n",
    "\n",
    "# Validate that the file has a \"questions\" column\n",
    "if \"questions\" not in questions_df.columns:\n",
    "    raise ValueError(\"The Excel file must contain a 'questions' column.\")\n",
    "\n",
    "# Fetch the first 10 questions\n",
    "questions = questions_df[\"questions\"].head(3)\n",
    "\n",
    "# Define a function to get answers from the OpenAI GPT API\n",
    "def get_answer(question):\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        # Return the content of the response\n",
    "        print(response)\n",
    "        print(response['choices'])\n",
    "        return response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Iterate over the questions and get answers\n",
    "answers = []\n",
    "for question in questions:\n",
    "    answer = get_answer(question)\n",
    "    answers.append(answer)\n",
    "\n",
    "# Create a DataFrame with questions and answers\n",
    "output_df = pd.DataFrame({\"Question\": questions, \"Answer\": answers})\n",
    "\n",
    "# Display the first 10 questions with answers in the notebook\n",
    "print(output_df.to_string(index=False))  # Print DataFrame in a readable format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d4102-bd01-4cac-a7af-cd407726fd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fc10a8d-9edf-4c08-96c0-6073599a3464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                       Question                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Answer\n",
      "\"If a car is traveling faster than the speed of light, can it go back in time?\" According to our current understanding of physics, specifically Einstein's theory of relativity, it is not possible for any object with mass to reach or exceed the speed of light. The energy required to accelerate an object to the speed of light would be infinite, which is not possible. As such, the concept of a car (or anything else) traveling faster than light and going back in time is more a topic of science fiction than actual science. However, the field of quantum physics is constantly evolving, and who knows what we may learn in the future.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "openai.api_key = \"sk-proj-KFc9i31o6cQseftLCXagf0oo2eaxgT3BlbkFJIDsuMe4YZLcjpzbYkVp42kfc-HqlkKpoCT2TLUYi_HV1DgV_6RJxmzgwGCAuS2ifP9J4LEeHUA\"  # Replace with your actual OpenAI API key\n",
    "\n",
    "# Load the questions from the Excel file\n",
    "file_path = \"only_question.xlsx\"  # Ensure the file is in the same directory or provide the full path\n",
    "questions_df = pd.read_excel(file_path)\n",
    "\n",
    "# Validate that the file has a \"questions\" column\n",
    "if \"questions\" not in questions_df.columns:\n",
    "    raise ValueError(\"The Excel file must contain a 'questions' column.\")\n",
    "\n",
    "# Fetch the first 3 questions (you can modify the number here)\n",
    "questions = questions_df[\"questions\"].head(1)\n",
    "\n",
    "# Define a function to get answers from the OpenAI GPT API\n",
    "def get_answer(question):\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",  # Ensure the model name is correct\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        \n",
    "        # Extract the answer from the response object\n",
    "        \n",
    "        # answer = response['choices'][0]['message']['content']\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Iterate over the questions and get answers\n",
    "answers = []\n",
    "for question in questions:\n",
    "    answer = get_answer(question)\n",
    "    answers.append(answer)\n",
    "\n",
    "# Create a DataFrame with questions and answers\n",
    "output_df = pd.DataFrame({\"Question\": questions, \"Answer\": answers})\n",
    "\n",
    "# Display the first 3 questions with answers in the notebook\n",
    "print(output_df.to_string(index=False))  # Print DataFrame in a readable format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9e989cb-b708-4159-a373-7651d2605691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers for the first 3 questions saved successfully to questions_with_answers.xlsx\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "openai.api_key = \"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\"  # Replace with your actual OpenAI API key\n",
    "\n",
    "# Load the questions from the Excel file\n",
    "file_path = \"only_question.xlsx\"  # Ensure the file is in the same directory or provide the full path\n",
    "questions_df = pd.read_excel(file_path)\n",
    "\n",
    "# Validate that the file has a \"questions\" column\n",
    "if \"questions\" not in questions_df.columns:\n",
    "    raise ValueError(\"The Excel file must contain a 'questions' column.\")\n",
    "\n",
    "# Limit the DataFrame to the first 3 questions\n",
    "questions_df = questions_df.head(3)\n",
    "\n",
    "# Define a function to get answers from the OpenAI GPT API\n",
    "def get_answer(question):\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",  # Ensure the model name is correct\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        \n",
    "        # Extract the answer from the response object\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Apply the get_answer function to each question and store the answers in a new column 'answers'\n",
    "questions_df['answers'] = questions_df['questions'].apply(get_answer)\n",
    "\n",
    "# Save the updated DataFrame with answers to a new Excel file (optional)\n",
    "output_file_path = \"questions_with_answers.xlsx\"\n",
    "questions_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Answers for the first 3 questions saved successfully to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b7b9ad-1067-4dc4-bdd0-1aa29a2e00ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question: \"A confidence interval tells you the exact range in which the true value lies.\"\n",
      "Processing question: \"If a model is overfitting, it’s still useful as long as it fits the training data well.\"\n",
      "Processing question: \"If you have 95% confidence in your results, there’s a 95% chance the hypothesis is true.\"\n",
      "Processing question: \"The larger the sample size, the more accurate your results will be.\"\n",
      "Processing question: \"Missing data can be ignored if it’s only a small portion of the dataset.\"\n",
      "Processing question: \"Statistical significance means that the result is important in practice.\"\n",
      "Processing question: \"Statistical tests always provide definitive answers.\"\n",
      "Processing question: \"You should never round numbers when reporting statistical results.\"\n",
      "Processing question: \"If you have a large p-value, the result is not significant and therefore unimportant.\"\n",
      "Processing question: \"Results can be generalized to a larger population even if the sample isn’t random.\"\n",
      "Processing question: \"If a test fails to reject the null hypothesis, the null hypothesis is true.\"\n",
      "Processing question: \"If the p-value is smaller than 0.05, we can say the null hypothesis is false.\"\n",
      "Processing question: \"If a correlation is 0.8, there is a very strong relationship between the variables.\"\n",
      "Processing question: \"If a dataset is skewed, we should always use the mean to represent central tendency.\"\n",
      "Processing question: \"Once you have a large sample, you don’t need to worry about biases in data.\"\n",
      "Processing question: \"If two groups have the same p-value, they have the same effect size.\"\n",
      "Processing question: \"Confidence intervals that do not include zero prove that the effect is real.\"\n",
      "Processing question: \"If the data is normally distributed, we don’t need to worry about outliers.\"\n",
      "Processing question: \"If the R-squared value is high, the model is a good fit.\"\n",
      "Processing question: \"P-values are the only measure of statistical significance.\"\n",
      "Processing question: \"A higher p-value means the effect is not important.\"\n",
      "Processing question: \"If a model is 95% accurate, it means it performs well.\"\n",
      "Processing question: \"If the data is normally distributed, you don’t need to check the assumptions of your statistical test.\"\n",
      "Processing question: \"The sample mean is always the best measure of central tendency.\"\n",
      "Processing question: \"A large sample size guarantees accurate results.\"\n",
      "Processing question: \"If a correlation is high, you can predict one variable from the other.\"\n",
      "Processing question: \"If your data is highly variable, it means your model is bad.\"\n",
      "Processing question: \"All statistical tests require a large sample size to be valid.\"\n",
      "Processing question: \"The null hypothesis can never be true, so it’s always rejected.\"\n",
      "Processing question: \"You should never use the mean when you have outliers in your data.\"\n",
      "Processing question: \"Outliers always need to be removed from the data.\"\n",
      "Processing question: \"If your data is normally distributed, you can use any statistical test.\"\n",
      "Processing question: \"A p-value of 0.01 is 10 times stronger evidence against the null hypothesis than a p-value of 0.10.\"\n",
      "Processing question: \"The best model is the one with the highest R-squared value.\"\n",
      "Processing question: \"A sample size of 30 is always large enough for normality to apply.\"\n",
      "Processing question: \"The only way to improve a model is to add more features.\"\n",
      "Processing question: \"A hypothesis test can never fail to reject the null hypothesis if there is a real effect.\"\n",
      "Processing question: \"Regression analysis can tell you whether one variable causes another.\"\n",
      "Processing question: \"If you have a significant p-value, you don’t need to worry about the size of the effect.\"\n",
      "Processing question: \"A statistical model that fits the training data well will perform well on new data.\"\n",
      "Processing question: \"You don’t need to worry about the p-value if your sample size is large enough.\"\n",
      "Processing question: \"If the data is normally distributed, you can use parametric tests with no other checks.\"\n",
      "Processing question: \"If two variables have no correlation, there is no relationship between them.\"\n",
      "Processing question: \"Statistical significance means the effect is important in practice.\"\n",
      "Processing question: \"If the p-value is greater than 0.05, it means the data is not significant.\"\n",
      "Processing question: \"The more significant variables you include in a model, the better the model will be.\"\n",
      "Processing question: \"If you obtain a result with a 99% confidence interval, it means there’s a 99% chance that the true value lies within that interval.\"\n",
      "Processing question: \"The more observations you have, the less important the quality of the data becomes.\"\n",
      "Processing question: \"You should always use the same statistical test for different datasets, no matter their characteristics.\"\n",
      "Processing question: \"The mean is always the best measure of central tendency.\"\n",
      "Processing question: \"If a model has a high p-value, it means the model is useless.\"\n",
      "Processing question: \"If you don’t find statistical significance, it means there is no effect.\"\n",
      "Processing question: \"Statistical tests can prove that a hypothesis is true.\"\n",
      "Processing question: \"A model is good if it predicts the outcome accurately on training data.\"\n",
      "Processing question: \"The p-value threshold for significance should always be 0.05.\"\n",
      "Processing question: \"A larger sample size will always make your results more reliable.\"\n",
      "Processing question: \"You can compare the means of two groups using a t-test, regardless of how the data is distributed.\"\n",
      "Processing question: \"If a model has a low R-squared value, it means the model is bad.\"\n",
      "Processing question: \"If two variables have a strong correlation, one must be the cause of the other.\"\n",
      "Processing question: \"You should always aim for a p-value below 0.05 when designing your experiment.\"\n",
      "Processing question: \"A non-significant result means the experiment was a failure.\"\n",
      "Processing question: \"A correlation coefficient of 1.0 means a perfect positive relationship.\"\n",
      "Processing question: \"A significant result means the model is valid.\"\n",
      "Processing question: \"If the p-value is 0.03, it means there’s only a 3% chance that the null hypothesis is true.\"\n",
      "Processing question: \"The mode is always the best measure of central tendency for skewed data.\"\n",
      "Processing question: \"Random sampling is unnecessary as long as you have a large sample size.\"\n",
      "Processing question: \"If your data has high variance, it means your model is poor.\"\n",
      "Processing question: \"Outliers should always be removed from the data before analysis.\"\n",
      "Processing question: \"All statistical tests are equally valid for all types of data.\"\n",
      "Processing question: \"A large p-value means there is no effect.\"\n",
      "Processing question: \"If your model isn’t perfect, it means it’s useless.\"\n",
      "Answers for the first questions saved successfully to dddddquestions_with_answers.xlsx\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "# Set up the OpenAI API key\n",
    "openai.api_key = \"sk-proj-PirjYMqZTbkFJGgMbVXh9lF9RmBzSY_3TY9oUzqYv05azF9plFCSDJDVZ4Q-AsKFUN95GP9SLwCeg0IcOyONCoA\"  # Replace with your actual OpenAI API key\n",
    "\n",
    "# Load the questions from the Excel file\n",
    "file_path = \"only_question.xlsx\"  # Ensure the file is in the same directory or provide the full path\n",
    "questions_df = pd.read_excel(file_path)\n",
    "\n",
    "# Validate that the file has a \"questions\" column\n",
    "if \"questions\" not in questions_df.columns:\n",
    "    raise ValueError(\"The Excel file must contain a 'questions' column.\")\n",
    "\n",
    "# # Limit the DataFrame to the first 3 questions\n",
    "# questions_df = questions_df.head(3)\n",
    "\n",
    "# Define a function to get answers from the OpenAI GPT API\n",
    "def get_answer(question):\n",
    "    try:\n",
    "        # Print the current question being processed\n",
    "        print(f\"Processing question: {question}\")\n",
    "        \n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4\",  # Ensure the model name is correct\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        \n",
    "        # Extract the answer from the response object\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Apply the get_answer function to each question and store the answers in a new column 'answers'\n",
    "questions_df['answers'] = questions_df['questions'].apply(get_answer)\n",
    "\n",
    "# Save the updated DataFrame with answers to a new Excel file (optional)\n",
    "output_file_path = \"dddddquestions_with_answers.xlsx\"\n",
    "questions_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Answers for the first questions saved successfully to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fb4986-e203-4f89-af8f-cc22b96ad97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034e968-eefd-441c-9596-bec020e9a66b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
